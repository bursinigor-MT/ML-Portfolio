{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2773b18c",
   "metadata": {},
   "source": [
    "Мы случайно пока собирали наш бардак в файлы train.ipynb и test.ipynb видимо где-то открутили/прикрутили фич (потому что код из разных файлов кидали) и итоговая точность на public вместо 97.63 (до 23:59:59 25.10.2025) стала 97.65 (посылка в 00:52 26.10.2025). Старую модель уже не знаем как восстановить (мы сами не в курсе какие там были настройки). В общем надеемся, что из-за этой \"оплошности\" не будет нюансов и наше положение в итоговой таблице не изменится в обоих посылках. Немного мы опоздали с превращением наших файлов в итоговый формат, приносим извинения!\n",
    "\n",
    "С уважением, команда rucode-2025-ai-0633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1838484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263f043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('interactions_private_test.csv')\n",
    "items = pd.read_csv('items.csv')\n",
    "users = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a730e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_csv.copy(deep=True)\n",
    "test = test.merge(items, on='item_id', how='left')\n",
    "test = test.merge(users, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01bc739",
   "metadata": {},
   "source": [
    "# Определения функций для выгрузки моделей и пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd33f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(X, cols):\n",
    "  X = X.copy()\n",
    "\n",
    "  X = X.drop(cols, axis=1)\n",
    "  return X\n",
    "\n",
    "def cosine_lr(iter, max_iter=1000):\n",
    "  min_lr = 0.0005\n",
    "  max_lr = 0.1\n",
    "  lr = min_lr + .5 * (max_lr - min_lr) * (1 + np.cos((iter / max_iter) * np.pi))\n",
    "\n",
    "  return lr\n",
    "\n",
    "def preprocessing_int_feature(X):\n",
    "  X = X.copy()\n",
    "\n",
    "  X['film_age'] = (X['release_year'].max() - X['release_year'])\n",
    "\n",
    "  X['age_bin'] = pd.qcut(X['film_age'],\n",
    "                         q=3,\n",
    "                         labels=['new', 'mid_age_film', 'old'],\n",
    "                         duplicates='drop')\n",
    "\n",
    "  X['total_dur']= np.log1p(X['total_dur'] / 60000)\n",
    "  X['total_dur_bin'] = pd.qcut(X['total_dur'],\n",
    "                              q = 5, \n",
    "                              labels=['very_short', 'short', 'mid', 'long', 'very_long'],\n",
    "                              duplicates='drop')\n",
    "\n",
    "\n",
    "  X['totalD_ageR_Ratio'] = X['total_dur']/(X['age_rating'] + 1) \n",
    "  X['film_age'] = (X['release_year'].max() - X['release_year']) \n",
    "  X['is_old_small_watch'] = (X['total_dur_bin'].isin(['short', 'very_short']) & X['last_d_count_watch'] < 7)\n",
    "  X['is_long_with_pop_actor'] = (X['total_dur_bin'].isin(['long', 'very_log']) & X['actors'] > X['actors'].quantile(.75)) \n",
    "  X['potential_power'] = X['actors'] * X['directors']\n",
    "\n",
    "\n",
    "\n",
    "  for col in ['total_dur_bin', 'age_bin']:\n",
    "    dummies = pd.get_dummies(X[col])\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X = X.drop(col, axis=1)\n",
    "\n",
    "  return X\n",
    "\n",
    "def preprocessing_cat_feature(X):\n",
    "  X = X.copy()\n",
    "\n",
    "  X['content_type'] = X['content_type'].map({'film':1, 'series':0})\n",
    "  X['sex'] = X['sex'].map({'Ж' : 1, 'М': 0, 'UNKNOWN':-1})\n",
    "\n",
    "  age_map = {'age_35_44' : 40,\n",
    "             'age_25_34' : 29,\n",
    "             'age_55_64' : 60,\n",
    "             'age_45_54' : 49,\n",
    "             'age_18_24' : 21,\n",
    "             'age_65_inf' : 65,\n",
    "             'UNKNOWN' : 0}\n",
    "\n",
    "  X['age'] = X['age'].map(age_map)\n",
    "\n",
    "  income_map = {'income_0_20' : 10,\n",
    "                'income_20_40' : 30,\n",
    "                'income_40_60' : 50,\n",
    "                'income_60_90' : 75,\n",
    "                'income_90_150' : 120,\n",
    "                'income_150_inf' : 120,\n",
    "                'UNKNOWN' : 0}\n",
    "\n",
    "  X['income'] = X['income'].map(income_map)\n",
    "\n",
    "\n",
    "  max_dt = pd.to_datetime(X['last_watch_dt']).dt.normalize().max()\n",
    "  X['last_watch_dt'] = pd.to_datetime(X['last_watch_dt']).dt.normalize()\n",
    "  X['last_d_count_watch'] = (max_dt - X['last_watch_dt']).dt.days.astype(np.int64)\n",
    "  X = X.drop('last_watch_dt', axis=1)\n",
    "\n",
    "  X['exp_down_lst_day_wtch'] = np.exp(-X['last_d_count_watch'] / 30)\n",
    "\n",
    "  return X\n",
    "\n",
    "class FichaEncode(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, cols=['actors']):\n",
    "    self.cols = cols\n",
    "    self.map_cols = { col:{} for i,col in enumerate(self.cols)}\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "\n",
    "    for col in self.cols:\n",
    "      for members in X[col]:\n",
    "\n",
    "        if members is np.nan:\n",
    "          continue\n",
    "\n",
    "        members = members.split(', ')\n",
    "        for member in members:\n",
    "          self.map_cols[col][member] = self.map_cols[col].get(member, 0) + 1\n",
    "\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "\n",
    "\n",
    "    for col in self.cols:\n",
    "      col_lst = X[col].str.split(', ')\n",
    "      sums = col_lst.apply(lambda actors: sum(self.map_cols[col].get(actor, 0) for actor in actors))\n",
    "      X[col] = np.log1p(sums)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "  def set_output(self, transform=None):\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc2013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_weights = joblib.load('model_weights.joblib')\n",
    "\n",
    "model_xgb_loaded = loaded_weights['model_xgb']\n",
    "model_lgbm_loaded = loaded_weights['model_lgbm']\n",
    "preprocessing = loaded_weights['processing_pipeline'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9332deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = preprocessing.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a64cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model_xgb_loaded.predict_proba(data_test) * 0.3 + \n",
    "               model_lgbm_loaded.predict_proba(data_test) * (1 - 0.3))\n",
    "\n",
    "test_csv['watched_pct'] = predictions[:, 1]\n",
    "\n",
    "# Если нужен ответ вида true/false \n",
    "# test_csv['watched_pct'] = predictions[:, 1] >= 0.5\n",
    "\n",
    "test_csv.to_csv('output_model.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
